## ğŸš€ PySpark Bike Sharing Analysis - Initial Implementation

### ğŸ“‹ **RÃ©sumÃ© des changements**

Cette PR introduit une analyse complÃ¨te des donnÃ©es de vÃ©los partagÃ©s de Chicago utilisant PySpark pour traiter plus de 1.1 million de trajets.

### âœ¨ **FonctionnalitÃ©s ajoutÃ©es**

#### **ğŸ” Analyses de donnÃ©es (6 analyses complÃ¨tes)**
- â±ï¸ **DurÃ©e moyenne des trajets par jour** - Identification des patterns temporels
- ğŸ“ˆ **Nombre de trajets quotidiens** - Analyse de la frÃ©quentation
- ğŸš‰ **Stations les plus populaires par mois** - Insights gÃ©ographiques  
- ğŸ” **Top 3 stations par jour (2 derniÃ¨res semaines)** - Tendances rÃ©centes
- ğŸ‘¥ **Analyse par genre** - Comparaison durÃ©e trajets Hommes vs Femmes
- ğŸ‘¶ğŸ‘´ **Analyse par Ã¢ge** - Top 10 Ã¢ges trajets longs/courts

#### **ğŸ› ï¸ Infrastructure technique**
- ğŸ³ **Containerisation Docker** avec Spark 3.0.1
- ğŸ“Š **Harmonisation intelligente des schÃ©mas** (formats 2019 vs 2020)
- ğŸ’¾ **Export automatique des rapports** en CSV
- ğŸ§ª **Suite de tests unitaires** avec pytest
- âš¡ **Optimisations Spark** (cache, mÃ©moire, partitioning)

### ğŸ“Š **DonnÃ©es traitÃ©es**
- **2019 Q4** : 704,054 trajets (12 colonnes)
- **2020 Q1** : 426,887 trajets (13 colonnes)  
- **Total** : **1,130,941 trajets analysÃ©s**

### ğŸ¯ **Insights clÃ©s dÃ©couverts**
- **Station dominante** : Canal St & Adams St (6,564+ trajets/mois)
- **SaisonnalitÃ©** : -70% d'activitÃ© entre octobre et novembre
- **DurÃ©e moyenne** : ~500 secondes avec variations mÃ©tÃ©o
- **Patterns** : Pics d'usage jours ouvrables vs weekends

### ğŸ—‚ï¸ **Fichiers ajoutÃ©s**
```
â”œâ”€â”€ main.py                     # Script principal d'analyse PySpark
â”œâ”€â”€ test_main.py               # Tests unitaires complets  
â”œâ”€â”€ docker-compose.yml         # Orchestration des services
â”œâ”€â”€ Dockerfile                 # Image personnalisÃ©e Spark
â”œâ”€â”€ requirements.txt           # DÃ©pendances Python
â”œâ”€â”€ setup.py                   # Configuration package
â”œâ”€â”€ README.md                  # Documentation complÃ¨te
â”œâ”€â”€ LICENSE                    # Licence MIT
â”œâ”€â”€ .gitignore                # Exclusions Git
â”œâ”€â”€ data/                     # Fichiers sources (ZIP)
â””â”€â”€ reports/                  # Rapports CSV gÃ©nÃ©rÃ©s
```

### ğŸš€ **Comment tester**

1. **Build l'image Docker :**
   ```bash
   docker build --tag=pyspark-bike-analysis .
   ```

2. **Lancer l'analyse complÃ¨te :**
   ```bash
   docker-compose up run
   ```

3. **ExÃ©cuter les tests :**
   ```bash
   docker-compose up test
   ```

### âœ… **Tests**
- [x] Chargement des donnÃ©es ZIP
- [x] Harmonisation des schÃ©mas
- [x] 6 analyses fonctionnelles  
- [x] Export CSV automatique
- [x] Tests unitaires passent
- [x] Docker build successful

### ğŸ“ˆ **Performance**
- Traitement de 1.1M+ lignes en ~2-3 minutes
- Utilisation mÃ©moire optimisÃ©e (2GB driver/executor)
- Cache intelligent pour performances

### ğŸ”„ **Prochaines Ã©tapes potentielles**
- [ ] Ajout d'analyses gÃ©ospatiales avec les coordonnÃ©es lat/lng
- [ ] Dashboard interactif avec visualisations
- [ ] Pipeline automatisÃ© avec Apache Airflow
- [ ] DÃ©ploiement sur cluster Spark

---

**Type de changement** : âœ¨ Nouvelle fonctionnalitÃ©  
**Impact** : ğŸ”¥ Major - Nouveau projet complet  
**Documentation** : âœ… Ã€ jour
